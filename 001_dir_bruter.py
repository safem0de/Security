import requests
import argparse
from urllib.parse import urljoin

def brute_force_dirs(url, wordlist):
    try:
        with open(wordlist, 'r') as f:
            paths = [line.strip() for line in f.readlines()]
    except FileNotFoundError:
        print(f"[!] à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œ: {wordlist}")
        return

    print(f"[+] à¹€à¸£à¸´à¹ˆà¸¡à¸¢à¸´à¸‡ request à¹„à¸›à¸¢à¸±à¸‡ {url}")
    for path in paths:
        full_url = urljoin(url, path)
        try:
            r = requests.get(full_url, timeout=5)
            if r.status_code in [200, 301, 302, 403]:
                print(f"[+] à¸žà¸š path: {full_url} ({r.status_code})")
        except requests.RequestException:
            continue

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ðŸ›  Directory Bruteforcer Tool')
    parser.add_argument('url', help='URL à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢ (à¹€à¸Šà¹ˆà¸™ https://example.com/)')
    parser.add_argument('wordlist', help='Path à¹„à¸›à¸¢à¸±à¸‡à¹„à¸Ÿà¸¥à¹Œ wordlist.txt')
    args = parser.parse_args()

    brute_force_dirs(args.url, args.wordlist)
